# ğŸ“¦ gRPC Sales Aggregator

A lightweight backend service built in **pure Python + gRPC** (no web frameworks) that processes large CSV files by aggregating departmental sales data.  
The system includes a **Next.js frontend** for file uploads and an **Envoy proxy** for gRPC-Web compatibility.

---

## ğŸš€ Features

- **Pure Python backend** using `grpcio` (no Django/FastAPI/Flask)
- **Unary UploadCSV** RPC with file upload and streaming CSV processing (low memory)
- **Envoy proxy** for browser compatibility (gRPC-Web â†’ gRPC)
- **Next.js frontend** with file upload UI and download link
- **Memory-efficient** CSV aggregation (streamed I/O)
- **Dockerized** for quick setup (backend + envoy + frontend)
- **Unit tests** for aggregation logic

---

## ğŸ§± Architecture Overview

```
Browser (Next.js)
       â†“  gRPC-Web
[ Envoy Proxy :8081 ]
       â†“  HTTP/2 gRPC
[ Python gRPC Server :50051 ]
       â†³ Processes CSVs line-by-line
       â†³ Stores results under /storage/results
       â†³ Serves files via :8080 HTTP
```

---

## ğŸ—‚ï¸ Project Structure

```
grpc_sales_aggregator/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                 # gRPC + HTTP servers
â”‚   â”‚   â”œâ”€â”€ services/sales_service.py
â”‚   â”‚   â”œâ”€â”€ core/aggregator.py      # CSV processing logic
â”‚   â”‚   â”œâ”€â”€ core/file_manager.py    # File paths, UUIDs
â”‚   â”‚   â””â”€â”€ config.py
â”‚   â”œâ”€â”€ generated/                  # Auto-generated protobuf stubs
â”‚   â”œâ”€â”€ proto/sales.proto           # gRPC interface
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ tests/
â”‚       â””â”€â”€ test_aggregator.py
â”‚
â”œâ”€â”€ envoy/
â”‚   â”œâ”€â”€ envoy.yaml                  # gRPC-Web proxy config
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ next.config.js
â”‚   â”œâ”€â”€ src/app/page.tsx
â”‚   â”œâ”€â”€ src/components/UploadForm.tsx
â”‚   â””â”€â”€ src/lib/grpcClient.ts
â”‚
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## ğŸ§© Protobuf Definition

`backend/proto/sales.proto`
```proto
syntax = "proto3";

package sales.v1;

service SalesService {
  rpc UploadCSV (UploadRequest) returns (UploadResponse);
  rpc DownloadResult (DownloadRequest) returns (DownloadResponse);
}

message UploadRequest {
  bytes data = 1;
  string filename = 2;
}

message UploadResponse {
  string result_id = 1;
  string download_url = 2;
  uint64 rows = 3;
  uint64 bad_rows = 4;
  uint64 departments = 5;
  double elapsed_sec = 6;
}

message DownloadRequest {
  string result_id = 1;
}

message DownloadResponse {
  bytes data = 1;
}
```

---

## ğŸ§° Requirements

- Python 3.11+
- Node.js 20+
- Docker + Docker Compose
- protoc (Protocol Buffers compiler)
- gRPC-Web plugin (for frontend stub generation)

---

## âš™ï¸ Setup

### 1ï¸âƒ£ Clone and enter the project
```bash
git clone https://github.com/abrs7/grpc-sales-aggregator.git
cd grpc-sales-aggregator
```

### 2ï¸âƒ£ Generate gRPC stubs

#### Backend:
```bash
python -m grpc_tools.protoc -I=backend/proto   --python_out=backend/generated   --grpc_python_out=backend/generated   backend/proto/sales.proto
```

#### Frontend:
```bash
cd frontend
npm install
npm run proto
```

---

## ğŸ³ Run with Docker

From the **project root**:
```bash
docker compose up --build
```

Wait until you see:
```
[gRPC] Listening on 0.0.0.0:50051
[HTTP] Serving results from .../storage/results
```

Then open:
ğŸ‘‰ [http://localhost:3000](http://localhost:3000)

---

## ğŸ–¥ï¸ Ports

| Service | Port | Description |
|----------|------|-------------|
| Frontend (Next.js) | **3000** | Web UI |
| Envoy Proxy | **8081** | gRPC-Web endpoint |
| gRPC Backend | **50051** | Python gRPC service |
| HTTP File Server | **8080** | Result CSV downloads |

---

## ğŸ§ª Testing (Backend)

Run local tests:

```bash
cd backend
pytest -q
```

Sample test in `tests/test_aggregator.py` validates CSV aggregation output.

---

## ğŸ§  Algorithm & Complexity

The backend uses **streaming I/O** to process arbitrarily large CSVs without loading them fully into memory.

| Operation | Complexity |
|------------|-------------|
| Time | **O(n)** â€” each row processed once |
| Memory | **O(d)** â€” where *d* = number of unique departments |

---

## ğŸ”’ Security Notes

- No authentication is enabled (for demo/test simplicity)
- Production deployments should add:
  - Auth tokens or mTLS for gRPC
  - Signed download URLs (for result files)
  - Rate limiting on upload endpoints

---

## ğŸ§° Useful Commands

### Rebuild everything cleanly
```bash
docker compose build --no-cache
docker compose up
```

### View logs
```bash
docker compose logs -f backend
```

### Stop all containers
```bash
docker compose down
```

---

## âœ… Deliverables Summary

| Deliverable | Status |
|--------------|--------|
| Python gRPC backend | âœ… |
| CSV streaming processor | âœ… |
| Frontend gRPC-Web upload UI | âœ… |
| Envoy proxy for gRPC-Web | âœ… |
| Unit tests (Pytest) | âœ… |
| Dockerized setup | âœ… |
| README + documentation | âœ… |

---

## ğŸ§‘â€ğŸ’» Author
**Abraham Asrat**  
ğŸ“§ [abrahamasrat791@gmail.com](mailto:abrahamasrat791@gmail.com)  
ğŸ’¼ [LinkedIn / GitHub profile link]